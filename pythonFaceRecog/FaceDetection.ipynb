{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import socket\n",
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "# folder containing images\n",
    "path = r'C:\\Users\\Andrew Kim\\Desktop\\Python Script\\Photos'\n",
    "\n",
    "list_names=[]\n",
    "list_faces=[]\n",
    "\n",
    "# find all images in the folder\n",
    "for im in os.listdir(path):\n",
    "    # verify the format of the image\n",
    "    if im[-4:] == '.jpg':\n",
    "        list_names.append(im[:-4])\n",
    "        temp_face = face_recognition.load_image_file(path+'\\\\'+im)\n",
    "        list_faces.append(face_recognition.face_encodings(temp_face)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['andrew', 'ben', 'ehsan', 'fay', 'kelby', 'tibor', 'will']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to Listen\n",
      "Connection address: ('129.8.194.8', 49859)\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-668acd496e2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#Get data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mpilImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mpilImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpilImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLIP_LEFT_RIGHT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "#Takes care of error of image sizes\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "TCP_IP = '129.8.232.106'\n",
    "TCP_PORT = 11000\n",
    "\n",
    "print('Starting to Listen')\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.bind((TCP_IP, TCP_PORT))\n",
    "s.listen(1)\n",
    "conn, addr = s.accept()\n",
    "print('Connection address:', addr)\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "sendData = ''\n",
    "check = True\n",
    "\n",
    "while True:\n",
    "    check = True\n",
    "    #Get data\n",
    "    data = conn.recv(1024000)\n",
    "    pilImage = Image.open(io.BytesIO(data))\n",
    "    pilImage = pilImage.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    #frame = cv2.cvtColor(np.array(pilImage), cv2.COLOR_RGB2BGR)\n",
    "    frame = cv2.cvtColor(np.array(pilImage), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    #small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Find all the faces and face encodings in the current frame of video\n",
    "#     face_locations = face_recognition.face_locations(small_frame)\n",
    "#     face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        # See if the face is a match for the known face(s)\n",
    "        match = face_recognition.compare_faces(list_faces, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        for i in range(len(match)):\n",
    "            if match[i]:\n",
    "                name = list_names[i]\n",
    "\n",
    "        face_names.append(name)\n",
    "\n",
    "    count = 0\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "#         top *= 4\n",
    "#         right *= 4\n",
    "#         bottom *= 4\n",
    "#         left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        \n",
    "#         if check:\n",
    "#             sendData = name + ' ' + str(top) + ' ' + str(right) + ' ' + str(bottom) + ' ' + str(left) + '\\n'\n",
    "#             conn.send(str.encode(sendData))\n",
    "#             check = False\n",
    "        #print(sendData)\n",
    "        count += 1\n",
    "        if count == 2: break\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    cv2.waitKey(1)\n",
    "    #Find all faces in the image\n",
    "    \n",
    "    #User Input\n",
    "#     if check:\n",
    "#         conn.send(str.encode('Nothing -100 -100 -100 -100\\n'))\n",
    "    #To close\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "conn.close()\n",
    "\n",
    "# Release handle to the webcam\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
